{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'laughney': AnnData object with n_obs × n_vars = 40505 × 19222\n",
       "     obs: 'raw', 'major', 'major_hallmark_corrected', 'tier_0', 'tier_1', 'tier_2', 'tier_3', 'tier_0_hallmark_corrected'\n",
       "     var: 'gene_symbol'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"data/laughney20_lung/\")\n",
    "adatas = {}\n",
    "adatas['laughney'] = anndata.read_h5ad(path / \"adata.h5ad\")\n",
    "adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 40505 × 19222\n",
       "    obs: 'raw', 'major', 'major_hallmark_corrected', 'tier_0', 'tier_1', 'tier_2', 'tier_3', 'tier_0_hallmark_corrected'\n",
       "    var: 'gene_symbol'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anndata.read_h5ad(path / \"adata.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40505x19222 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 65068723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas['laughney'].X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 表格特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>major</th>\n",
       "      <th>major_hallmark_corrected</th>\n",
       "      <th>tier_0</th>\n",
       "      <th>tier_1</th>\n",
       "      <th>tier_2</th>\n",
       "      <th>tier_3</th>\n",
       "      <th>tier_0_hallmark_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MACROPHAGE</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Macrophage</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DENDRITIC</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Dendritic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40500</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40501</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40502</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40503</th>\n",
       "      <td>Tm</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>T</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40504</th>\n",
       "      <td>MACROPHAGE</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>Immune</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Macrophage</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40505 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              raw  major major_hallmark_corrected tier_0  tier_1    tier_2   \n",
       "0              Tm  Tumor                   Immune  Tumor  Immune  Lymphoid  \\\n",
       "1      MACROPHAGE  Tumor                   Immune  Tumor  Immune   Myeloid   \n",
       "2       DENDRITIC  Tumor                   Immune  Tumor  Immune   Myeloid   \n",
       "3              Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "4              Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "...           ...    ...                      ...    ...     ...       ...   \n",
       "40500          Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "40501          Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "40502          Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "40503          Tm  Tumor                   Immune  Tumor  Immune  Lymphoid   \n",
       "40504  MACROPHAGE  Tumor                   Immune  Tumor  Immune   Myeloid   \n",
       "\n",
       "           tier_3 tier_0_hallmark_corrected  \n",
       "0               T                    Normal  \n",
       "1      Macrophage                    Normal  \n",
       "2       Dendritic                    Normal  \n",
       "3               T                    Normal  \n",
       "4               T                    Normal  \n",
       "...           ...                       ...  \n",
       "40500           T                    Normal  \n",
       "40501           T                    Normal  \n",
       "40502           T                    Normal  \n",
       "40503           T                    Normal  \n",
       "40504  Macrophage                    Normal  \n",
       "\n",
       "[40505 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas['laughney'].obs.astype('str')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 40505 × 19222\n",
       "    obs: 'raw', 'major', 'major_hallmark_corrected', 'tier_0', 'tier_1', 'tier_2', 'tier_3', 'tier_0_hallmark_corrected'\n",
       "    var: 'gene_symbol'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anndata.read_h5ad(path / \"adata.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # import dataset\n",
    "        data = anndata.read_h5ad(path / \"adata.h5ad\") \n",
    "        # x1\n",
    "        self.x1 = data.X\n",
    "        # x2\n",
    "        x2 = data.obs.astype('str')\n",
    "        le = LabelEncoder()\n",
    "        le_count = 0\n",
    "        for col in x2:\n",
    "            if x2[col].dtype == 'object':\n",
    "                le.fit(x2[col])\n",
    "                x2[col] = le.transform(x2[col])\n",
    "                le_count += 1\n",
    "        self.x2 = x2.drop('tier_0_hallmark_corrected',axis=1).to_numpy()\n",
    "        self.y = torch.tensor(x2['tier_0_hallmark_corrected'].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x2[idx], self.y[idx]\n",
    "dataset = MyDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=200, shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for xx ,yy in train_loader:\n",
    "    print(yy)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11,  3,  3,  0,  3,  1,  3],\n",
       "        [14,  6,  3,  1,  3,  0,  4],\n",
       "        [11,  3,  3,  0,  3,  1,  3],\n",
       "        [ 7,  3,  3,  0,  3,  1,  2],\n",
       "        [ 1,  6,  3,  1,  3,  1,  1],\n",
       "        [13,  3,  3,  0,  3,  0,  4],\n",
       "        [ 4,  6,  1,  1,  1,  2,  7],\n",
       "        [19,  6,  3,  1,  3,  0,  6],\n",
       "        [18,  6,  3,  1,  3,  0,  6],\n",
       "        [17,  6,  3,  1,  3,  0,  6],\n",
       "        [18,  6,  3,  1,  3,  0,  6],\n",
       "        [17,  6,  3,  1,  3,  0,  6],\n",
       "        [ 4,  6,  1,  1,  1,  2,  7],\n",
       "        [17,  6,  3,  1,  3,  0,  6],\n",
       "        [ 5,  6,  2,  1,  2,  2,  7],\n",
       "        [ 4,  1,  1,  0,  1,  2,  7],\n",
       "        [17,  6,  3,  1,  3,  0,  6],\n",
       "        [ 8,  6,  3,  1,  3,  1,  5],\n",
       "        [18,  3,  3,  0,  3,  0,  6],\n",
       "        [17,  6,  3,  1,  3,  0,  6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均匀采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # import dataset\n",
    "        data = anndata.read_h5ad(path / \"adata.h5ad\") \n",
    "        sc.pp.log1p(data)\n",
    "        # x1\n",
    "        self.x1 = data.X\n",
    "        # x2\n",
    "        x2 = data.obs.astype('str')\n",
    "        le = LabelEncoder()\n",
    "        le_count = 0\n",
    "        for col in x2:\n",
    "            if x2[col].dtype == 'object':\n",
    "                le.fit(x2[col])\n",
    "                x2[col] = le.transform(x2[col])\n",
    "                le_count += 1\n",
    "        self.y = torch.tensor(x2['tier_0_hallmark_corrected'].values, dtype=torch.long)\n",
    "        x2 = x2.drop('tier_0_hallmark_corrected',axis=1).to_numpy()\n",
    "        scaler = StandardScaler()\n",
    "        x2_scaler = scaler.fit_transform(x2)\n",
    "        self.x2 = x2_scaler\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.x1[idx].toarray()[0]\n",
    "        return x1,self.x2[idx], self.y[idx]\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        class_sample_count = np.unique(self.y, return_counts=True)[1]\n",
    "        weight = 1. / class_sample_count\n",
    "        samples_weight = weight[self.y]\n",
    "        return torch.from_numpy(samples_weight)\n",
    "    \n",
    "dataset = MyDataset()\n",
    "samples_weight = dataset.get_sample_weights()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=200, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for x1,x2,y in train_loader:\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch\n",
    "import anndata\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,mode='train'):\n",
    "        # import dataset\n",
    "        data = anndata.read_h5ad(Path(\"data/laughney20_lung/\") / \"adata.h5ad\") \n",
    "        # x1\n",
    "        self.x1 = data.X\n",
    "        # x2\n",
    "        x2 = data.obs.astype('str')\n",
    "        le = LabelEncoder()\n",
    "        le_count = 0\n",
    "        for col in x2:\n",
    "            if x2[col].dtype == 'object':\n",
    "                le.fit(x2[col])\n",
    "                x2[col] = le.transform(x2[col])\n",
    "                le_count += 1\n",
    "        self.y = torch.tensor(x2['tier_0_hallmark_corrected'].values, dtype=torch.long)\n",
    "        x2 = x2.drop('tier_0_hallmark_corrected',axis=1).to_numpy()\n",
    "        scaler = StandardScaler()\n",
    "        x2_scaler = scaler.fit_transform(x2)\n",
    "        self.x2 = x2_scaler\n",
    "        # split\n",
    "        np.random.seed(0)\n",
    "        random_arr = np.random.rand(len(self.y))\n",
    "        mask = random_arr < 0.8\n",
    "        if mode == 'train':\n",
    "            self.x1, self.x2, self.y =  self.x1[mask], self.x2[mask], self.y[mask]\n",
    "        else:\n",
    "            mask = random_arr >= 0.8\n",
    "            self.x1, self.x2, self.y =  self.x1[mask], self.x2[mask], self.y[mask]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.x1[idx].toarray()[0]\n",
    "        return x1,self.x2[idx], self.y[idx]\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        class_sample_count = np.unique(self.y, return_counts=True)[1]\n",
    "        weight = 1. / class_sample_count\n",
    "        samples_weight = weight[self.y]\n",
    "        return torch.from_numpy(samples_weight)\n",
    "train_dataset = MyDataset('train')\n",
    "test_dataset = MyDataset('test')\n",
    "samples_weight = train_dataset.get_sample_weights()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=200, sampler=sampler)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for x1,x2,y in test_loader:\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 19222])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
